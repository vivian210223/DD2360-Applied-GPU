{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OLW4OLO5bKma","executionInfo":{"status":"ok","timestamp":1701033310301,"user_tz":-60,"elapsed":248,"user":{"displayName":"翁紹育","userId":"08915612866540316427"}},"outputId":"a8f87fed-3083-4ed1-c59d-a0aefb22a4cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Nov 26 21:15:08 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","source":["!nvcc --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pOrmAZ20bcRc","executionInfo":{"status":"ok","timestamp":1701033312689,"user_tz":-60,"elapsed":367,"user":{"displayName":"翁紹育","userId":"08915612866540316427"}},"outputId":"efbc7b79-bbaa-4dcd-990e-d47fd7b040d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2022 NVIDIA Corporation\n","Built on Wed_Sep_21_10:33:58_PDT_2022\n","Cuda compilation tools, release 11.8, V11.8.89\n","Build cuda_11.8.r11.8/compiler.31833905_0\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jSLOhDEDbfQf","executionInfo":{"status":"ok","timestamp":1701033345081,"user_tz":-60,"elapsed":1808,"user":{"displayName":"翁紹育","userId":"08915612866540316427"}},"outputId":"ff8a2713-0aac-4bcc-c9a7-0122483b29a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/GPU/2/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IUNLvuKKbjT3","executionInfo":{"status":"ok","timestamp":1701033347913,"user_tz":-60,"elapsed":365,"user":{"displayName":"翁紹育","userId":"08915612866540316427"}},"outputId":"dcf20d2a-96eb-4eef-dd75-ac355998369e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/GPU/2\n"]}]},{"cell_type":"code","source":["!nvcc -o ex1.out ex1.cu"],"metadata":{"id":"WDnad-OUcMYD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! ./ex1.out 131070 512"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xx6woJXQdenD","executionInfo":{"status":"ok","timestamp":1701030408205,"user_tz":-60,"elapsed":481,"user":{"displayName":"翁紹育","userId":"08915612866540316427"}},"outputId":"6c4c2553-34bf-4751-fc23-2c857bfa2889"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The input length is 131070\n","The output is equal to the reference"]}]},{"cell_type":"code","source":["! nvprof ./ex1.out 75979 1024"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B5quL0kgH_Rq","executionInfo":{"status":"ok","timestamp":1700996758405,"user_tz":-60,"elapsed":350,"user":{"displayName":"翁紹育","userId":"08915612866540316427"}},"outputId":"71ea6071-007f-4982-bee5-21b48b09a29a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The input length is 75979\n","==6211== NVPROF is profiling process 6211, command: ./ex1.out 75979 1024\n","The output is equal to the reference==6211== Profiling application: ./ex1.out 75979 1024\n","==6211== Profiling result:\n","            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n"," GPU activities:   66.97%  156.32us         3  52.105us  52.063us  52.159us  [CUDA memcpy HtoD]\n","                   28.74%  67.071us         1  67.071us  67.071us  67.071us  [CUDA memcpy DtoH]\n","                    4.29%  10.016us         1  10.016us  10.016us  10.016us  vecAdd(double*, double*, double*, int)\n","      API calls:   98.65%  124.31ms         3  41.437ms  3.5820us  124.30ms  cudaMalloc\n","                    1.08%  1.3621ms         4  340.53us  164.89us  713.33us  cudaMemcpy\n","                    0.12%  150.04us         3  50.011us  4.1170us  128.62us  cudaFree\n","                    0.09%  116.01us       101  1.1480us     131ns  49.162us  cuDeviceGetAttribute\n","                    0.02%  30.339us         1  30.339us  30.339us  30.339us  cudaLaunchKernel\n","                    0.02%  27.958us         1  27.958us  27.958us  27.958us  cuDeviceGetName\n","                    0.01%  7.2340us         1  7.2340us  7.2340us  7.2340us  cuDeviceGetPCIBusId\n","                    0.01%  6.4840us         1  6.4840us  6.4840us  6.4840us  cudaDeviceSynchronize\n","                    0.00%  1.6620us         3     554ns     206ns  1.2340us  cuDeviceGetCount\n","                    0.00%  1.1340us         2     567ns     188ns     946ns  cuDeviceGet\n","                    0.00%     532ns         1     532ns     532ns     532ns  cuModuleGetLoadingMode\n","                    0.00%     487ns         1     487ns     487ns     487ns  cuDeviceTotalMem\n","                    0.00%     224ns         1     224ns     224ns     224ns  cuDeviceGetUuid\n"]}]},{"cell_type":"code","source":["! ncu -o profile2 ./ex1.out 131070 512"],"metadata":{"id":"0qGm3m5UiZ8V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701030418690,"user_tz":-60,"elapsed":1373,"user":{"displayName":"翁紹育","userId":"08915612866540316427"}},"outputId":"363fb2cc-270b-4c2d-da6e-30792ed985a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The input length is 131070\n","==PROF== Connected to process 1778 (/content/drive/MyDrive/GPU/2/ex1.out)\n","==PROF== Profiling \"vecAdd\" - 0: 0%....50%....100% - 8 passes\n","==PROF== Disconnected from process 1778\n","The output is equal to the reference==PROF== Report: /content/drive/MyDrive/GPU/2/profile2.ncu-rep\n"]}]},{"cell_type":"code","source":["! ncu -i /content/drive/MyDrive/GPU/2/profile2.ncu-rep --page details"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RehLRp4dICT2","executionInfo":{"status":"ok","timestamp":1701030424982,"user_tz":-60,"elapsed":615,"user":{"displayName":"翁紹育","userId":"08915612866540316427"}},"outputId":"15290d7f-1d8b-4529-8776-e5efa78eb2e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1778] ex1.out@127.0.0.1\n","  vecAdd(double *, double *, double *, int), 2023-Nov-26 20:26:56, Context 1, Stream 7\n","    Section: GPU Speed Of Light Throughput\n","    ---------------------------------------------------------------------- --------------- ------------------------------\n","    DRAM Frequency                                                           cycle/nsecond                           4.70\n","    SM Frequency                                                             cycle/usecond                         548.67\n","    Elapsed Cycles                                                                   cycle                          6,940\n","    Memory [%]                                                                           %                          60.73\n","    DRAM Throughput                                                                      %                          60.73\n","    Duration                                                                       usecond                          12.64\n","    L1/TEX Cache Throughput                                                              %                          30.89\n","    L2 Cache Throughput                                                                  %                          30.54\n","    SM Active Cycles                                                                 cycle                       5,304.02\n","    Compute (SM) [%]                                                                     %                          23.62\n","    ---------------------------------------------------------------------- --------------- ------------------------------\n","    WRN   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n","          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n","          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n","          whether there are values you can (re)compute.                                                                 \n","\n","    Section: Launch Statistics\n","    ---------------------------------------------------------------------- --------------- ------------------------------\n","    Block Size                                                                                                        512\n","    Function Cache Configuration                                                                  cudaFuncCachePreferNone\n","    Grid Size                                                                                                         256\n","    Registers Per Thread                                                   register/thread                             16\n","    Shared Memory Configuration Size                                                 Kbyte                          32.77\n","    Driver Shared Memory Per Block                                              byte/block                              0\n","    Dynamic Shared Memory Per Block                                             byte/block                              0\n","    Static Shared Memory Per Block                                              byte/block                              0\n","    Threads                                                                         thread                        131,072\n","    Waves Per SM                                                                                                     3.20\n","    ---------------------------------------------------------------------- --------------- ------------------------------\n","    WRN   A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    \n","          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       \n","          occupancy of the kernel. This kernel launch results in 3 full waves and a partial wave of 16 thread blocks.   \n","          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   \n","          up to 25.0% of the total kernel runtime with a lower occupancy of 23.1%. Try launching a grid with no         \n","          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  \n","          a grid. See the Hardware Model                                                                                \n","          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      \n","          details on launch configurations.                                                                             \n","\n","    Section: Occupancy\n","    ---------------------------------------------------------------------- --------------- ------------------------------\n","    Block Limit SM                                                                   block                             16\n","    Block Limit Registers                                                            block                              8\n","    Block Limit Shared Mem                                                           block                             16\n","    Block Limit Warps                                                                block                              2\n","    Theoretical Active Warps per SM                                                   warp                             32\n","    Theoretical Occupancy                                                                %                            100\n","    Achieved Occupancy                                                                   %                          76.95\n","    Achieved Active Warps Per SM                                                      warp                          24.62\n","    ---------------------------------------------------------------------- --------------- ------------------------------\n","    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     \n","          theoretical (100.0%) and measured achieved occupancy (76.9%) can be the result of warp scheduling overheads   \n","          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    \n","          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                \n","          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           \n","          optimizing occupancy.                                                                                         \n","\n"]}]},{"cell_type":"code","source":["!nvcc -o ex2.out ex2.cu"],"metadata":{"id":"hYnncbTSHyi3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! ./ex2.out 32 128 128 128 128"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sW5gwASuaTBu","executionInfo":{"status":"ok","timestamp":1701036733514,"user_tz":-60,"elapsed":617,"user":{"displayName":"翁紹育","userId":"08915612866540316427"}},"outputId":"1d36ef96-dc8f-41de-da00-c6c8453ba45d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input matrix dim (128 x 128) (128 x 128) (128 x 128)\n","The output of host are equal to reference\n","kernel:288.000000, H2D:237.000000, D2H:156.000000\n","kernel:42.290749%, H2D:34.801762%, D2H:22.907489%"]}]},{"cell_type":"code","source":["! nvprof ./ex2.out 32 128 128 128 128"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WCuHTaHTb5dt","executionInfo":{"status":"ok","timestamp":1701036737518,"user_tz":-60,"elapsed":667,"user":{"displayName":"翁紹育","userId":"08915612866540316427"}},"outputId":"b20815cc-18b4-47f7-d528-8a86755fd417"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input matrix dim (128 x 128) (128 x 128) (128 x 128)\n","==30449== NVPROF is profiling process 30449, command: ./ex2.out 32 128 128 128 128\n","The output of host are equal to reference\n","kernel:303.000000, H2D:257.000000, D2H:196.000000\n","==30449== Profiling application: ./ex2.out 32 128 128 128 128\n","==30449== Profiling result:\n","            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n"," GPU activities:   82.28%  247.61us         1  247.61us  247.61us  247.61us  gemm(double*, double*, double*, int, int, int, int)\n","                   13.68%  41.183us         3  13.727us  13.568us  13.984us  [CUDA memcpy HtoD]\n","                    4.04%  12.160us         1  12.160us  12.160us  12.160us  [CUDA memcpy DtoH]\n","      API calls:   99.53%  253.43ms         3  84.476ms  3.5980us  253.42ms  cudaMalloc\n","                    0.19%  485.31us         4  121.33us  68.379us  189.78us  cudaMemcpy\n","                    0.11%  268.00us         3  89.333us  3.1800us  249.15us  cudaDeviceSynchronize\n","                    0.08%  194.63us       101  1.9270us     286ns  88.606us  cuDeviceGetAttribute\n","                    0.07%  166.63us         3  55.544us  4.3260us  149.12us  cudaFree\n","                    0.01%  34.246us         1  34.246us  34.246us  34.246us  cudaLaunchKernel\n","                    0.01%  28.792us         1  28.792us  28.792us  28.792us  cuDeviceGetName\n","                    0.00%  8.4240us         1  8.4240us  8.4240us  8.4240us  cuDeviceGetPCIBusId\n","                    0.00%  1.8070us         3     602ns     311ns  1.1680us  cuDeviceGetCount\n","                    0.00%     953ns         2     476ns     298ns     655ns  cuDeviceGet\n","                    0.00%     676ns         1     676ns     676ns     676ns  cuDeviceTotalMem\n","                    0.00%     428ns         1     428ns     428ns     428ns  cuDeviceGetUuid\n","                    0.00%     390ns         1     390ns     390ns     390ns  cuModuleGetLoadingMode\n","kernel:40.079365%, H2D:33.994709%, D2H:25.925926%"]}]},{"cell_type":"code","source":["! ./ex2.out 32 128 128 128 128"],"metadata":{"id":"MUzKvLL5hkv0"},"execution_count":null,"outputs":[]}]}